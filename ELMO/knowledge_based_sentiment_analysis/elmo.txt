기존 방식
- data를 tokenizing
- tokenized data를 word2vec로 vectorizing
- 그러면 vector = {word_vectors, num_of_words, vectorized_contents} 를 얻을 수 있다.
- 여기서 word_vectors를 통해 cluster를 생성한다. (DBSCAN 밀도 기반 클러스터링)
- 그리고, 전체 데이터에서 문장 단위로 


